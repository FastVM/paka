
def paka_tokenize_stream1(bsrc, keywords, ops_flat) {
    xop = 0
    while xop < length(ops_flat) {
        op = ops_flat[xop]
        if stream_starts_swith(bsrc, op) {
            stream_skip(bsrc, length(op))
            return [token.op, op, bsrc[1]]
        }
        xop = xop + 1
    }
    first = stream_peek(bsrc)
    if first == ' ' {
        stream_skip1(bsrc)
        return paka_tokenize_stream1(bsrc, keywords, ops_flat)
    }
    if first == 10 {
        stream_skip1(bsrc)
        return paka_tokenize_stream1(bsrc, keywords, ops_flat)
    }
    if first == '#' {
        stream_skip1(bsrc)
        while true {
            cur = stream_read(bsrc)
            if cur == 10 {
                return paka_tokenize_stream1(bsrc, keywords, ops_flat)
            }
        }
    }
    if first == '(' {
        return [token.open, stream_read(bsrc), bsrc[1]]
    }
    if first == ')' {
        return [token.close, stream_read(bsrc), bsrc[1]]
    }
    if first == '{' {
        return [token.open, stream_read(bsrc), bsrc[1]]
    }
    if first == '}' {
        return [token.close, stream_read(bsrc), bsrc[1]]
    }
    if first == '[' {
        return [token.open, stream_read(bsrc), bsrc[1]]
    }
    if first == ']' {
        return [token.close, stream_read(bsrc), bsrc[1]]
    }
    if first == ',' {
        return [token.comma, stream_read(bsrc), bsrc[1]]
    }
    if first == ''' {
        stream_skip1(bsrc)
        cur = stream_read(bsrc)
        if cur == "\\"[0] {
            cur = stream_read(bsrc)
            if stream_read() != ''' {
                puts("unterminated char literal")
                exit
            }
            if cur == 'n' {
                return [token.num, 10, bsrc[1]]
            } 
            if cur == "\""[0] {
                return [token.num, cur, bsrc[1]]
            }
            if cur == "\\"[0] {
                return [token.num, cur, bsrc[1]]
            }
        } else {
            if stream_read() != ''' {
                puts("unterminated char literal")
                exit
            }
            return [token.num, cur, bsrc[1]]
        }
    }
    if first == "\""[0] {
        stream_skip1(bsrc)
        ret = []
        while true {
            cur = stream_read(bsrc)
            if cur == 0 {
                puts("eof in str")
                exit
            }
            if cur == "\""[0] {
                return [token.str, ret, bsrc[1]]
            }
            if cur == "\\"[0] {
                cur = stream_read(bsrc)
                if cur == 'n' {
                    ret ~= [10]
                } 
                if cur == "\""[0] {
                    ret ~= ["\""[0]]
                }
                if cur == "\\"[0] {
                    ret ~= ["\\"[0]]
                }
            } else {
                ret ~= [cur]
            }
        }
        puts("bad char")
        exit
    }
    if char_isdigit(first) {
        n = 0
        while char_isdigit(stream_peek(bsrc)) {
            n = n * 10 + stream_read(bsrc) - '0'
        }
        return [token.num, n, bsrc[1]]
    }
    if char_id0(first) {
        xsrc = []
        while true {
            if char_id(stream_peek(bsrc)) {
                xsrc ~= [stream_read(bsrc)]
            } else {
                ki = 0
                while ki < length(keywords) {
                    if keywords[ki] == xsrc {
                        return [token.keyword, xsrc, bsrc[1]]
                    }
                    ki = ki + 1
                }
                return [token.ident, xsrc, bsrc[1]]
            }
        }
    }
    if first == 0 {
        return 0
    }
    puts(str_to_array("bad char: ") ~ [first])
    exit
}

def paka_tokenize(src) {
    keywords = ["while", "if", "else", "def", "enum", "return", "macro", "exit", "true", "false", "none"]
    ops_flat = ["<=", ">=", "==", "!=", "~=", "=", "~", "+", "-", "%", "*", "/", "<", ">"]
    ssrc = stream_new(src) 
    tokens = []
    while true {
        if stream_peek(ssrc) == 0 {
            return tokens
        }
        token = paka_tokenize_stream1(ssrc, keywords, ops_flat)
        if token == 0 {
            return tokens
        }
        tokens ~= [token]
    }
}
